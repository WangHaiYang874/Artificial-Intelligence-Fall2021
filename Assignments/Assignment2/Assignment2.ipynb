{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><center>Artificial Intelligence, Assignment 2</center></h2>\n",
    "\n",
    "<h3><center>Search agents</center></h3>\n",
    "\n",
    "<img src='imageAIAssignment002.jpeg' width=\"400\" height=\"400\">\n",
    "\n",
    "\n",
    "__Total:__ 27pts + 5pts\n",
    "\n",
    "__Given date:__ Tuesday September 28\n",
    "\n",
    "__Due date:__ Friday October 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1. A story of robots and batteries \n",
    "\n",
    "##### (15pts + 2pts)\n",
    "\n",
    "We consider the simple $12\\times12$ world depicted below. In this first exercise, we will study the behavior of an agent that can only see the immediately adjacent cells (that is it only sees the cells that are directly in front, behind, or on its left/right). Your agent is a simple robot that enters the maze from the bottom left cell and must reach the exit which is located on the uppermost rightmost cell. \n",
    "\n",
    "\n",
    "<img src='MAZE002.png' width=\"400\" height=\"400\">\n",
    "\n",
    "<p style=\"margin-bottom:1cm;\"></p>\n",
    "\n",
    "The objective of the agent is twofold:\n",
    "\n",
    "   - 1) It has to find the exit (In a first approach, we won't take any step cost into account), while avoiding all the holes.\n",
    "\n",
    "   - 2) It has to collect all the batteries.\n",
    "\n",
    "\n",
    "\n",
    "##### Question 1.1. (5pts) A simple reflex agent \n",
    "\n",
    "Using a simple while loop and follow the ideas discussed during the recitations to code a simple reflex agent that achieves this objective. When the agent faces a pit, it should avoid it. When the agent is on a cell containing a battery, it should collect it. Finally the agent can only move in the four immediately adjacent cells to its current position. When it sees no pit and there are no batteries in any of the adjacent cells, it should move at random. Consider adding on the order of 14 batteries and 18 holes (first manually, then at random) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Answer 1.1\n",
    "\n",
    "The below is a simple impletations of this simple reflex agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# an aux function\n",
    "def children(pos, avoids=[-1,-2]):\n",
    "    ret = []\n",
    "    x, y = pos\n",
    "    for xx in [x-1,x+1]:\n",
    "        if xx>= 0 and xx<shape[0] and (world[xx,y] not in avoids):\n",
    "            ret.append((xx,y))\n",
    "    for yy in [y-1,y+1]:\n",
    "        if yy>= 0 and yy<shape[1] and (world[x,yy] not in avoids):\n",
    "            ret.append((x,yy))\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def table_gen(shape=(12,12), num_bat=14,num_holes=18,num_walls=0 ,seed=1):\n",
    "    np.random.seed(seed)\n",
    "    size = shape[0]*shape[1]\n",
    "    \n",
    "    assert(size>5)\n",
    "    \n",
    "    world = np.zeros(size)\n",
    "    \n",
    "    # generating the batteries and holes randomly.\n",
    "    i = 0\n",
    "    while i < num_bat:\n",
    "        pos = np.random.randint(1,size-1)\n",
    "        if world[pos] == 0:\n",
    "            world[pos] = 1\n",
    "            i += 1\n",
    "    i = 0\n",
    "    while i < num_holes:\n",
    "        pos = np.random.randint(1, size-1)\n",
    "        # the initial/exit position cannot be a hole. \n",
    "        if world[pos] == 0:\n",
    "            world[pos] = -1\n",
    "            i += 1\n",
    "    i = 0\n",
    "    while i < num_walls:\n",
    "        pos = np.random.randint(1, size-1)\n",
    "        # the initial/exit position cannot be a hole. \n",
    "        if world[pos] == 0:\n",
    "            world[pos] = -2\n",
    "            i += 1\n",
    "\n",
    "    # -1 means there is a hole, 1 means there is a batteries, -2 means there is a wall. \n",
    "    \n",
    "    world = world.reshape(shape)\n",
    "    holes = np.array(np.where(world==-1))\n",
    "    batteries = np.array(np.where(world==1))\n",
    "    walls = np.array(np.where(world==-2))\n",
    "    \n",
    "    return (world, batteries, holes, batteries, walls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_reflex_agent() -> object:\n",
    "    # initial states\n",
    "    # selecting a random seed here\n",
    "    np.random.seed(5)\n",
    "    uncollected = set([tuple(i) for i in batteries.transpose()])\n",
    "    # this sets contains the uncollected batteries. \n",
    "    end_pos = (shape[0]-1,shape[1]-1)\n",
    "    curr_pos = (0, 0)\n",
    "    \n",
    "    while (len(uncollected) > 0) or (curr_pos != end_pos):\n",
    "        # update the agent's position\n",
    "        if world[curr_pos] == 1 and curr_pos in uncollected:\n",
    "            uncollected.discard(curr_pos)\n",
    "        next_positions = children(curr_pos)\n",
    "        for next_pos in next_positions:\n",
    "            if world[next_pos] == 1 and next_pos in uncollected:\n",
    "                curr_pos = next_pos\n",
    "                continue\n",
    "        curr_pos = next_positions[np.random.choice(len(next_positions))]\n",
    "        \n",
    "        yield (curr_pos, uncollected)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## animation of simple reflex agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = (12,12)\n",
    "num_bat = 14\n",
    "num_holes = 18\n",
    "num_walls = 0\n",
    "\n",
    "world, batteries, holes, battery, walls = table_gen(shape=(12,12), num_bat=14,num_holes=18,num_walls=0 ,seed=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "#### plotting, before running the agents\n",
    "fig, ax = plt.subplots()\n",
    "ax.matshow(np.zeros(shape=world.shape), cmap=plt.cm.BuGn)\n",
    "\n",
    "# the agent\n",
    "agent, = plt.plot([],[],marker='$ðŸ˜€$',ms=10,linestyle='',color='tan')\n",
    "\n",
    "# the holes and batterys\n",
    "plt.plot(holes[0], holes[1], marker='$âšª$', ms=10,color='black',linestyle='')\n",
    "uncol_batt, = plt.plot([], [], marker='$ðŸ”‹$',ms=10, linestyle='')\n",
    "\n",
    "# grid\n",
    "ax.set_xticks(np.arange(world.shape[0])-0.5,minor='true')\n",
    "ax.set_yticks(np.arange(world.shape[1])-0.5, minor='true')\n",
    "ax.grid(which='minor')\n",
    "ax.set_xticks([])\n",
    "ax.set_xticklabels([]) \n",
    "ax.set_yticks([]) \n",
    "ax.set_yticklabels([])\n",
    "plt.xlim((-0.5,world.shape[0]-0.5))\n",
    "plt.ylim((-0.5,world.shape[1]-0.5))\n",
    "plt.grid()\n",
    "\n",
    "\n",
    "def update_anime(frame):\n",
    "    curr_pos, uncollected = frame\n",
    "    agent.set_data(curr_pos[0],curr_pos[1])\n",
    "    if len(uncollected):\n",
    "        un_x, un_y = np.array(list(uncollected)).transpose()\n",
    "        uncol_batt.set_data(un_x,un_y)\n",
    "    else:\n",
    "        uncol_batt.set_data([],[])\n",
    "    return (agent,uncol_batt)\n",
    "    \n",
    "ani = animation.FuncAnimation(fig, update_anime, interval=100,frames=simple_reflex_agent(),blit=True,save_count=len([1 for i in simple_reflex_agent()]))\n",
    "ani.save('simple reflex animation.gif')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See the animation here. (Notice that since I have selected random seed, when you run it again, you will get the same animation. So probably you set a different seed to get different animations)\n",
    "\n",
    "<img src=\"simple reflex animation.gif\" width=\"750\" align=\"center\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question 1.2. (5pts) Search agent\n",
    "\n",
    "We will now assume that our agent has a map of the world. On top of the pits from above, the world now also contains walls, which are additional obstacles in the search for the exit.\n",
    "\n",
    "Solve the problem using Breadth First search. The children of a node are given by the adjacent cells. Once you have the path to a battery, stores it. Then continue BFS from the location of this battery and store your second path,.... Proceed like this until you have all the batteries. From the last battery find the exit.  \n",
    "\n",
    "<img src='Maze003.png' width=\"400\" height=\"400\">\n",
    "\n",
    "<p style=\"margin-bottom:1cm;\"></p>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Anwser 1.2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = (18,18)\n",
    "num_bat = 20\n",
    "num_holes = 18\n",
    "num_walls = 18\n",
    "\n",
    "world, batteries, holes, battery,walls = table_gen(shape=shape, num_bat=num_bat,num_holes=num_holes,num_walls=num_walls,seed=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minimal_path(start, end=end_pos):\n",
    "    '''\n",
    "    this returns a path from curr_pos to the exit.\n",
    "    '''\n",
    "    if start == end:\n",
    "        return []\n",
    "    \n",
    "    explored = [start]\n",
    "    q = [start]\n",
    "    bp = {}\n",
    "    bp[start] = None\n",
    "    \n",
    "    while (end not in explored) and (len(q) > 0):\n",
    "        new_pos = []\n",
    "        for pos in q:\n",
    "            for child in children(pos):\n",
    "                if child not in explored:\n",
    "                    explored.append(child)\n",
    "                    new_pos.append(child)\n",
    "                    bp[child] = pos\n",
    "        q = new_pos\n",
    "    \n",
    "    if end in explored:\n",
    "        ret = []\n",
    "        curr_pos = end\n",
    "        while bp[curr_pos] != None:\n",
    "            ret.append(curr_pos)\n",
    "            curr_pos = bp[curr_pos]\n",
    "        ret.reverse()\n",
    "        return ret\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_next_bat(path):\n",
    "    collected = set([i for i in path if world[i]==1])\n",
    "    start = path[-1]\n",
    "    \n",
    "    if len(collected) == num_bat:\n",
    "        npath = minimal_path(start,end_pos)\n",
    "        if npath!=None:\n",
    "            return path + npath\n",
    "        else: return None\n",
    "\n",
    "    explored = [start]\n",
    "    q = [start]\n",
    "    bp = {}\n",
    "    bp[start] = None\n",
    "    found = False\n",
    "    \n",
    "    while (not found) and (len(q) > 0):\n",
    "        new_pos = []\n",
    "        for pos in q:\n",
    "            for child in children(pos):\n",
    "                if child not in explored:\n",
    "                    explored.append(child)\n",
    "                    new_pos.append(child)\n",
    "                    bp[child] = pos\n",
    "                    if world[child] == 1 and (child not in collected):\n",
    "                        found = True\n",
    "                        batt = child\n",
    "        q = new_pos\n",
    "    \n",
    "    if found:\n",
    "        npath = []\n",
    "        curr_pos = batt\n",
    "        while bp[curr_pos] != None:\n",
    "            npath.append(curr_pos)\n",
    "            curr_pos = bp[curr_pos]\n",
    "        npath.reverse()\n",
    "        \n",
    "        return path + npath\n",
    "    else: \n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_agent() -> object:\n",
    "    # initial states\n",
    "    collected = set()\n",
    "    # this sets contains the collected batteries. \n",
    "    end_pos = (shape[0]-1,shape[1]-1)\n",
    "    start_pos = (0, 0)\n",
    "    \n",
    "    path = [start_pos]\n",
    "    \n",
    "    while path[-1] != end_pos:\n",
    "        path = find_next_bat(path)\n",
    "        yield path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "#### plotting, before running the agents\n",
    "fig, ax = plt.subplots()\n",
    "ax.matshow(np.zeros(shape=world.shape), cmap=plt.cm.BuGn)\n",
    "\n",
    "# the agent\n",
    "agent, = plt.plot([],[],marker='$ðŸ˜€$',ms=10,linestyle='',color='tan')\n",
    "\n",
    "# the holes and batterys\n",
    "plt.plot(holes[0], holes[1], marker='$âšª$', ms=10,color='black',linestyle='')\n",
    "plt.plot(walls[0], walls[1], marker='$ðŸ”´$', ms=10,color='black',linestyle='')\n",
    "uncol_batt, = plt.plot([], [], marker='$ðŸ”‹$',ms=10, linestyle='')\n",
    "\n",
    "# grid\n",
    "ax.set_xticks(np.arange(world.shape[0])-0.5,minor='true')\n",
    "ax.set_yticks(np.arange(world.shape[1])-0.5, minor='true')\n",
    "ax.grid(which='minor')\n",
    "ax.set_xticks([])\n",
    "ax.set_xticklabels([]) \n",
    "ax.set_yticks([]) \n",
    "ax.set_yticklabels([])\n",
    "plt.xlim((-0.5,world.shape[0]-0.5))\n",
    "plt.ylim((-0.5,world.shape[1]-0.5))\n",
    "plt.grid()\n",
    "\n",
    "i=0\n",
    "def update_anime(frame):\n",
    "    x,y = np.array(frame).transpose()\n",
    "    agent.set_data(x,y)\n",
    "    uncollected = [tuple(i) for i in batteries.transpose() if tuple(i) not in frame]\n",
    "    if len(uncollected):\n",
    "        un_x, un_y = np.array(list(uncollected)).transpose()\n",
    "        uncol_batt.set_data(un_x,un_y)\n",
    "    else:\n",
    "        uncol_batt.set_data([],[])\n",
    "    return (agent,uncol_batt)\n",
    "    \n",
    "ani = animation.FuncAnimation(fig, update_anime, interval=1000,frames=search_agent(),blit=True)\n",
    "ani.save('first search reflex animation.gif')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See the animation here. (Notice that since I have selected random seed, when you run it again, you will get the same animation. So probably you set a different seed to get different animations)\n",
    "\n",
    "<img src=\"first search reflex animation.gif\" width=\"750\" align=\"center\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question 1.3. (5pts) Informed search agent\n",
    "\n",
    "In this third question, we will use an informed search strategy to improve our agent. We want to use as our heuristic the $\\ell_1$ distance to the closest battery that has not been picked. Code a Best First Search agent whose heuristic changes as it picks up new batteries. As soon as it picked up the last battery, the heuristic becomes the $\\ell_1$ distance to the exit. You can assume that the cells have unitary side length. Also recall that the $\\ell_1$ distance is given by $\\|\\boldsymbol x_1 - \\boldsymbol x_2\\|_1 = |x_{11} - x_{21}| + |x_{12} - x_{22}|$ where $\\boldsymbol x_1 = (x_{11}, x_{12})$, $\\boldsymbol x_{2} = (x_{21}, x_{22})$.    \n",
    "\n",
    "\n",
    "<img src='Maze003.png' width=\"400\" height=\"400\">\n",
    "\n",
    "<p style=\"margin-bottom:1cm;\"></p>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating the table\n",
    "\n",
    "shape = (12,12)\n",
    "size = shape[0]*shape[1]\n",
    "\n",
    "num_bat = 14\n",
    "num_holes = 14\n",
    "num_wall = 8\n",
    "\n",
    "world = np.zeros(size)\n",
    "\n",
    "# it should not be 0, which would be the starting position. \n",
    "\n",
    "# generating the batteries, holes and walls randomly. \n",
    "# 0 means there is nothing\n",
    "# 1 means there is a battery\n",
    "# -1 means there is a wall or a hole.\n",
    "\n",
    "i = 0\n",
    "while i < num_bat:\n",
    "    pos = np.random.randint(0,size)\n",
    "    if world[pos] == 0:\n",
    "        world[pos] = 1\n",
    "        i += 1\n",
    "\n",
    "i = 0\n",
    "while i < num_holes:\n",
    "    pos = np.random.randint(1, size-1)\n",
    "    # the randint starts from 1 because the initial position cannot be a hole. \n",
    "    if world[pos] == 0:\n",
    "        world[pos] = -1\n",
    "        i += 1\n",
    "i = 0\n",
    "while i < num_bat:\n",
    "    pos = np.random.randint(0,size-1)\n",
    "    if world[pos] == 0:\n",
    "        world[pos] = 2\n",
    "        i += 1\n",
    "\n",
    "world = world.reshape(shape)\n",
    "holes = np.where(world==-1)\n",
    "batteries = np.where(world==1)\n",
    "walls = np.where(world==2)\n",
    "\n",
    "world[world==2] = -1\n",
    "# this merges the walls and holes as the same thing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial states\n",
    "collected = set()\n",
    "# this sets contains the collected batteries. \n",
    "end_pos = (shape[0]-1,shape[1]-1)\n",
    "start_pos = (0, 0)\n",
    "\n",
    "bat_coor = set(zip(batteries[0],batteries[1]))\n",
    "\n",
    "path = [start_pos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def informed_search(path):\n",
    "    collected = set([i for i in path if world[i]==1])\n",
    "    start = path[-1]\n",
    "    \n",
    "    if len(collected) == num_bat:\n",
    "        npath = minimal_path(start,end_pos)\n",
    "        if npath != None:\n",
    "            return path + npath\n",
    "        return None\n",
    "    \n",
    "    mindist = size*size\n",
    "    nextbat = None\n",
    "    \n",
    "    for bat in bat_coor:\n",
    "        if bat not in collected:\n",
    "            d = abs(bat[0] - start[0]) + abs(bat[1] - start[1])\n",
    "            if d < mindist:\n",
    "                mindist = d\n",
    "                nextbat = bat\n",
    "    \n",
    "    assert(nextbat!=None)\n",
    "    \n",
    "    npath = minimal_path(start, nextbat)\n",
    "    if npath != None:\n",
    "        return informed_search(path+npath)\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(0, 0)   (1, 0)   (1, 1)   (2, 1)   (2, 2)   (3, 2)   (2, 2)   (2, 3)   (2, 4)   (2, 5)   (3, 5)   (2, 5)   (1, 5)   (0, 5)   (1, 5)   (2, 5)   (3, 5)   (4, 5)   (4, 6)   (4, 7)   (4, 8)   (3, 8)   (3, 9)   (3, 10)   (2, 10)   (2, 11)   (1, 11)   (0, 11)   (1, 11)   (2, 11)   (3, 11)   (4, 11)   (4, 10)   (5, 10)   (6, 10)   (7, 10)   (8, 10)   (8, 11)   (9, 11)   (9, 10)   (9, 9)   (9, 8)   (9, 7)   (9, 6)   (9, 5)   (9, 4)   (10, 4)   (10, 3)   (11, 3)   (10, 3)   (10, 2)   (10, 1)   (10, 0)   (9, 0)   (8, 0)   (9, 0)   (10, 0)   (10, 1)   (10, 2)   (9, 2)   (9, 3)   (9, 4)   (9, 5)   (9, 6)   (10, 6)   (11, 6)   (11, 7)   (11, 8)   (11, 9)   (11, 10)   (11, 11)'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'   '.join([str(i) for i in informed_search([(0,0)])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Bonus (2pts) \n",
    "Generate and display the movie of the search for each of the questions above. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have displayed the movies for the simple reflex agent as well as the bfs agent. However, I don't really have the time to make a movie for the informed search agent again\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2. Rook Jumping\n",
    "\n",
    "##### (12pts + 3pts)\n",
    "\n",
    "In this second question, we consider a \"rook jumping\" maze. An example of such a maze is given below (the starting position is shown in red and the goal position is shown in green). \n",
    "\n",
    "\n",
    "\n",
    "<img src='RookMaze001.png' width=\"350\" height=\"350\">\n",
    "\n",
    "Each state in the maze has an associated jump number that provides the exact number of cells one may move horizontally or vertically in a straight line to change state. As an example, in the maze above, the first move may either be 2 cells on the right of (0,0) or 2 cells down to (2,0)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 2.1. Generate the maze (2pts)\n",
    "\n",
    "Start by completing the function Maze_generation which takes as argument the dimension of the maze as well as a maximum jump number (don't take it much larger than n/2) and returns a matrix of random integers between 0 and the maximum jump length. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Maze_generation(n, m=None):\n",
    "    '''function should return a random maze'''\n",
    "    if m:\n",
    "        return np.random.randint(low=1, high=m, size=(n,n))\n",
    "    else:\n",
    "        return np.random.randint(low=1, high=n//2, size=(n,n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_maze(maze):\n",
    "    fig, ax = plt.subplots()\n",
    "    max_val = max(maze.shape)    \n",
    "    ax.matshow(maze, cmap=plt.cm.Blues)\n",
    "\n",
    "    for i in range(max_val):\n",
    "        for j in range(max_val):\n",
    "            c = maze[j,i]\n",
    "            ax.text(i, j, str(c), va='center', ha='center')\n",
    "\n",
    "\n",
    "    ax.set_xticks([]) \n",
    "    ax.set_xticklabels([]) \n",
    "    ax.set_yticks([]) \n",
    "    ax.set_yticklabels([]) \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question 2.2. (5pts) Maze Evaluation\n",
    "\n",
    "We now want to solve the maze (or equivalently, make sure it has a solution)  \n",
    "\n",
    "Using _Breadth First Search_ (start with a reasonably small maze, e.g. 5 by 5), compute the minimum distance (depth number of moves) to each cell from the start cell (take the start cell to be the _uppermost leftmost_ cell). For this, keep track of a list of the depth distances to each node and update this list each time you encounter the corresponding node. Once BFS completed, return the minimum element from the list. \n",
    "\n",
    "Finally return the negative of the minimmum length of the path from the start to the goal and a large positive number (e.g. 1e6) if there is no such path.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Maze_Evaluation(maze):\n",
    "    \n",
    "    '''The function takes a maze (random n x n array of integers)\n",
    "    and should return the the minimum \n",
    "    distances of the start node to the goal'''\n",
    "    d = maze.shape(0)\n",
    "    dis = np.zeros(maze.shape) + np.inf\n",
    "    start = (0,0)\n",
    "    dis[start] = 0\n",
    "    \n",
    "    q = [start]\n",
    "\n",
    "    def children(pos):\n",
    "        x,y = pos\n",
    "        steps = maze[pos]\n",
    "        ret = []\n",
    "        for xx in [x - steps, x + steps]:\n",
    "            if xx>= 0 and xx < d:\n",
    "                ret.apped((xx,y))\n",
    "        for yy in [y - steps, y + steps]:\n",
    "            if yy>= 0 and yy < d:\n",
    "                ret.apped((x,yy))\n",
    "        return ret\n",
    "\n",
    "    \n",
    "    while len(q):\n",
    "        newq = []\n",
    "        for pos in q:\n",
    "            assert(np.isfinite(dis[pos]))\n",
    "            for child in children(pos):\n",
    "                if not np.isfinite(dis[child]):\n",
    "                    dis[child] = dis[pos] + 1\n",
    "                    newq.append(child)\n",
    "        q = newq\n",
    "    \n",
    "    if np.isfinite(dis[(-1,-1)]):\n",
    "        return - abs(dis[(-1,-1)])\n",
    "    else: return np.inf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question 2.3. (5pts) Stochastic local search (Hill climbing)\n",
    "\n",
    "Now that we have a way of representing each maze, we will try to improve our maze with a stochastic local search. In this question, each state in our graph will encode a whole maze. Our local search algorithm will work as follows\n",
    "\n",
    "- For a random, non goal cell, change the jump number to a different random legal jump number\n",
    "\n",
    "- Re-evaluate the start to goal distance according to the _Maze_Evaluation_ function that you implemented in Question 2.2.\n",
    "\n",
    "- If the objective function has not increased, accept the change and store the new maze if its evaluation is the best evaluated so far. Otherwise, reject the change and revert the cell to its previous jump number\n",
    "\n",
    "Perform a few iterations of Stochastich HC and return the RJM with the best (minimum) objective function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Maze_improvement(maze_init, maxIter):\n",
    "    \n",
    "    '''The function takes an initial Rook Jumping maze and \n",
    "    a maximum number of iterations as an input and returns \n",
    "    the improvement of the original maze obtained \n",
    "    through maxIter iteration of Stochastic Hill Descent'''\n",
    "    \n",
    "    maze = maze_init.copy()\n",
    "    steps = Maze_Evaluation(maze)\n",
    "    d = maze.shape[0]\n",
    "    \n",
    "    non_goal_cells = [(i//d,i%d) for i in range(d*d-1)]\n",
    "    \n",
    "    for i in range(maxIter):\n",
    "        non_goal_cell = non_goal_cells[np.random.choice(len(non_goal_cells))]\n",
    "        new_val = np.random.randint(1,d//2)\n",
    "        old_val = maze[non_goal_cell]\n",
    "        \n",
    "        maze[non_goal_cell] == new_val\n",
    "        score = Maze_Evaluation(maze)\n",
    "        if score < steps:\n",
    "            steps = score\n",
    "        else:\n",
    "            maze[non_goal_cell] = old_val\n",
    "    \n",
    "    return maze\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Bonus (3pts) Random Restart\n",
    "\n",
    "One problem with pure hill descent is that stochastic local search may become trapped in local minima. A possible escape strategy is to restart the search periodically. Another way of viewing this is that we iteratively perform pure hill descent, starting each descent at a random state. The end result is the best result from all descents.\n",
    "\n",
    "Add Random Restart to your 'Maze_improvement' function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Maze_improvement_RR(maze_init, max_iter_SHD, max_iter_RR):\n",
    "    \n",
    "    '''The function takes an initial (random) Rook Jumping maze and \n",
    "    a maximum number of iterations as an input and evaluates \n",
    "    the improvement of the original maze obtained \n",
    "    through max_iter_SHD iterations of Stochastic Hill Descent. \n",
    "    This process is repeated max_iter_RR times \n",
    "    (with different random initializations) and each of the \n",
    "    obtained solutions are stored. The max_iter_RR solutions are finally compared in \n",
    "    terms of the cost between the start and the goal node and \n",
    "    the best solution is returned as the final output'''\n",
    "    \n",
    "    ret = []\n",
    "    \n",
    "    for i in range(max_iter_RR):\n",
    "        \n",
    "        new_maze = Maze_improvement(maze_init,max_iter_SHD)\n",
    "        new_value = Maze_Evaluation(new_maze)\n",
    "        \n",
    "        ret.append(new_maze, new_value)\n",
    "        \n",
    "    ret.sort(key=lambda x:x[1])\n",
    "    \n",
    "    return ret[0]"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2a2a38fe34f8f37488d0fdf5c77f21fdb0e5a36ddb8afaa78e21eb865cd1002a"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
